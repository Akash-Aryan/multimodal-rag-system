{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG System Demo\n",
    "\n",
    "This notebook demonstrates how to use the multimodal RAG system to process and query documents, images, and audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's import the necessary modules and configure the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(str(Path('../src')))\n",
    "\n",
    "from multimodal_rag import MultimodalRAG, RAGConfig\n",
    "from loguru import logger\n",
    "\n",
    "# Configure logging\n",
    "logger.add(\"../logs/demo.log\", rotation=\"1 MB\")\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.yaml\"\n",
    "config = RAGConfig.from_yaml(config_path)\n",
    "\n",
    "# Display configuration\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"  - LLM Model: {config.llm.model_name}\")\n",
    "print(f\"  - Vector Store: {config.vector_store.provider}\")\n",
    "print(f\"  - Text Embedding Model: {config.embedding.text_model}\")\n",
    "print(f\"  - Supported Formats: {config.document_processing.supported_formats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the multimodal RAG system\n",
    "rag_system = MultimodalRAG(config)\n",
    "print(\"üöÄ Multimodal RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Ingestion\n",
    "\n",
    "Let's ingest some sample documents. You can place your files in the `../data/raw/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files are available for ingestion\n",
    "raw_data_dir = Path(\"../data/raw\")\n",
    "if raw_data_dir.exists():\n",
    "    files = list(raw_data_dir.glob(\"*\"))\n",
    "    print(f\"üìÅ Found {len(files)} files in raw data directory:\")\n",
    "    for file in files[:10]:  # Show first 10 files\n",
    "        print(f\"  - {file.name} ({file.suffix})\")\n",
    "else:\n",
    "    print(\"üìÅ Raw data directory not found. Creating sample structure...\")\n",
    "    raw_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"   Place your documents in ../data/raw/ to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest a Single File\n",
    "\n",
    "Let's create a sample text file and ingest it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample document\n",
    "sample_doc = raw_data_dir / \"sample_document.txt\"\n",
    "sample_content = \"\"\"\n",
    "# Multimodal RAG System Overview\n",
    "\n",
    "The multimodal RAG system is designed to handle various types of content:\n",
    "\n",
    "## Text Documents\n",
    "- PDF files with complex layouts\n",
    "- Microsoft Word documents\n",
    "- Plain text and Markdown files\n",
    "- Web pages and HTML content\n",
    "\n",
    "## Visual Content\n",
    "- Images with OCR text extraction\n",
    "- Charts and diagrams\n",
    "- Screenshots and photographs\n",
    "- Scanned documents\n",
    "\n",
    "## Audio Content\n",
    "- Voice recordings and meetings\n",
    "- Lectures and presentations\n",
    "- Podcasts and interviews\n",
    "- Music with lyrics\n",
    "\n",
    "The system uses advanced embedding models to create semantic representations\n",
    "of all content types, enabling unified search and retrieval across modalities.\n",
    "\n",
    "Key features include:\n",
    "- Offline operation with local LLMs\n",
    "- High-quality embeddings for semantic search\n",
    "- Configurable chunking and processing\n",
    "- Scalable vector storage\n",
    "- Context-aware response generation\n",
    "\"\"\"\n",
    "\n",
    "with open(sample_doc, 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_content)\n",
    "\n",
    "print(f\"üìÑ Created sample document: {sample_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the sample document\n",
    "result = await rag_system.ingest_file(str(sample_doc))\n",
    "\n",
    "print(\"‚úÖ Document ingested successfully!\")\n",
    "print(f\"üìä Ingestion results:\")\n",
    "print(f\"  - File: {result['file_path']}\")\n",
    "print(f\"  - File type: {result['file_type']}\")\n",
    "print(f\"  - Chunks created: {result['content_chunks']}\")\n",
    "print(f\"  - Status: {result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Ingestion\n",
    "\n",
    "If you have multiple files, you can ingest them all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest all files in the raw data directory\n",
    "if list(raw_data_dir.glob(\"*\")):\n",
    "    results = await rag_system.ingest_directory(str(raw_data_dir))\n",
    "    \n",
    "    # Show summary\n",
    "    successful = [r for r in results if r.get('status') == 'success']\n",
    "    failed = [r for r in results if r.get('status') == 'error']\n",
    "    total_chunks = sum(r.get('content_chunks', 0) for r in successful)\n",
    "    \n",
    "    print(f\"üìä Batch ingestion complete:\")\n",
    "    print(f\"  - Total files: {len(results)}\")\n",
    "    print(f\"  - Successful: {len(successful)}\")\n",
    "    print(f\"  - Failed: {len(failed)}\")\n",
    "    print(f\"  - Total chunks: {total_chunks}\")\n",
    "    \n",
    "    if failed:\n",
    "        print(\"\\n‚ùå Failed files:\")\n",
    "        for fail in failed:\n",
    "            print(f\"  - {fail.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"üìÅ No files found for batch ingestion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System Statistics\n",
    "\n",
    "Let's check the current state of the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get system statistics\n",
    "stats = await rag_system.get_system_stats()\n",
    "\n",
    "print(\"üìä System Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Querying the System\n",
    "\n",
    "Now let's query the system with different types of questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple question about content\n",
    "query = \"What types of content can the multimodal RAG system handle?\"\n",
    "\n",
    "result = await rag_system.query(\n",
    "    query=query,\n",
    "    query_type=\"text\",\n",
    "    top_k=3,\n",
    "    include_sources=True\n",
    ")\n",
    "\n",
    "print(f\"‚ùì Query: {query}\")\n",
    "print(f\"\\nü§ñ Response:\")\n",
    "print(result['response'])\n",
    "print(f\"\\nüìö Retrieved {result['retrieved_count']} relevant chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Source Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sources used in the response\n",
    "if result.get('sources'):\n",
    "    print(\"\\nüìñ Source Documents:\")\n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        doc = source.get('document', {})\n",
    "        score = source.get('score', 0)\n",
    "        metadata = doc.get('metadata', {})\n",
    "        \n",
    "        print(f\"\\n{i}. **Similarity Score**: {score:.3f}\")\n",
    "        print(f\"   **Source**: {metadata.get('source_file', 'Unknown')}\")\n",
    "        print(f\"   **Content**: {doc.get('text', '')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about specific features\n",
    "queries = [\n",
    "    \"What are the key features of the system?\",\n",
    "    \"How does the system handle audio content?\",\n",
    "    \"What embedding models are used?\",\n",
    "    \"What are the advantages of offline operation?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = await rag_system.query(query, top_k=2)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"‚ùì {query}\")\n",
    "    print(f\"\\nü§ñ {result['response']}\")\n",
    "    print(f\"üìä Confidence: {result.get('confidence_scores', [])[:1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Features\n",
    "\n",
    "### Save and Load Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current index\n",
    "await rag_system.save_index()\n",
    "print(\"üíæ Index saved successfully!\")\n",
    "\n",
    "# The index is automatically loaded on system initialization,\n",
    "# but you can also load it explicitly:\n",
    "# await rag_system.load_index()\n",
    "# print(\"üì• Index loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Query Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query session\n",
    "print(\"üîÑ Starting interactive query session...\")\n",
    "print(\"Type 'exit' to stop, or ask any question about your documents\")\n",
    "\n",
    "# Note: This might not work well in some Jupyter environments\n",
    "# For better interactive experience, use the CLI script: scripts/query.py -i\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        user_query = input(\"\\n‚ùì Your question: \").strip()\n",
    "        \n",
    "        if user_query.lower() in ['exit', 'quit', 'stop']:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_query:\n",
    "            continue\n",
    "        \n",
    "        # Process the query\n",
    "        result = await rag_system.query(user_query, top_k=3)\n",
    "        print(f\"\\nü§ñ {result['response']}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüëã Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in interactive session: {e}\")\n",
    "    print(\"üí° Tip: Use the CLI script for better interactive experience\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final system statistics\n",
    "final_stats = await rag_system.get_system_stats()\n",
    "\n",
    "print(\"üéØ Demo Complete!\")\n",
    "print(\"\\nüìä Final System State:\")\n",
    "for key, value in final_stats.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Add your own documents to ../data/raw/\")\n",
    "print(\"  2. Try the CLI scripts: scripts/ingest.py and scripts/query.py\")\n",
    "print(\"  3. Experiment with different query types and parameters\")\n",
    "print(\"  4. Configure different embedding models or LLMs\")\n",
    "print(\"  5. Explore the Docker deployment option\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Clear Index\n",
    "\n",
    "Uncomment and run this cell if you want to clear the index for a fresh start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clear the index\n",
    "# await rag_system.clear_index()\n",
    "# print(\"üóëÔ∏è Index cleared successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
